{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Módulo 4  - Metodologias de Aprendizado [Desafio do módulo] ",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOI3sUT1nxS6gVKKlw3HIHZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/franckepeixoto/IGTI-Analista-de-Machine-Learning/blob/main/M%C3%B3dulo_4_Metodologias_de_Aprendizado_%5BDesafio_do_m%C3%B3dulo%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnjIDWXCwxoh"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras.preprocessing.image import load_img,img_to_array\r\n",
        "import IPython.display as display\r\n",
        "import PIL as Image\r\n",
        "import tensorflow_hub as hub\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import os\r\n",
        "import pathlib\r\n",
        "!rm -rf views\r\n",
        "!mkdir ./views\r\n",
        "!nvidia-smi\r\n",
        "keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8xsBS_UxOBs"
      },
      "source": [
        "dataPath = keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', fname='flower_photos',untar=True)\r\n",
        "dataPath = pathlib.Path(dataPath)\r\n",
        "display.clear_output()\r\n",
        "dataPath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuj_kVTbyPYV"
      },
      "source": [
        "dataCount = len(list(dataPath.glob('*/*.jpg')))\r\n",
        "print('Total:\\t',dataCount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt_C-EHHyiIT"
      },
      "source": [
        "classNames = np.array([item.name for item in dataPath.glob('*') if item.name !='LICENSE.txt'])\r\n",
        "for name in classNames:\r\n",
        "  count = len(list(dataPath.glob(name+'/*')))\r\n",
        "  p = str(dataPath.absolute())+'/'+name+'/'\r\n",
        "  print(count,':\\t',name.strip(),'    (',p,')')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XsMoVB-1lAF"
      },
      "source": [
        "Data Pre-processing /  Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofAEOfWsziUs"
      },
      "source": [
        "def show_flowers(show=\"\",width=224,height=224, images_path ='/root/.keras/datasets/flower_photos/'):  \r\n",
        "  cols = 25\r\n",
        "  limit = 100\r\n",
        "  index = 0\r\n",
        "  images = list()\r\n",
        "  vertical_images=[]\r\n",
        "  images_path = images_path+show+'/'\r\n",
        "  for path in os.listdir(images_path):\r\n",
        "    index=index+1\r\n",
        "    if index%limit==0:\r\n",
        "        break\r\n",
        "    image = load_img(images_path+path, target_size=(width,height))\r\n",
        "    image= img_to_array(image) #to numpy\r\n",
        "    image_height, image_width, image_channel = image.shape\r\n",
        "    horizontal_side = np.ones((image_height, 5,  image_channel), dtype=np.float32)*255    \r\n",
        "    images.append(image)\r\n",
        "    images.append(horizontal_side)\r\n",
        "    if index%cols==0:\r\n",
        "      horizontal_image = np.hstack((images))\r\n",
        "      image_height, image_width, image_channel = horizontal_image.shape\r\n",
        "      vertical_side = np.ones((5, image_width,  image_channel), dtype=np.float32)*255\r\n",
        "      vertical_images.append(horizontal_image)\r\n",
        "      vertical_images.append(vertical_side)\r\n",
        "      images=list()\r\n",
        "  gallery=np.vstack((vertical_images)) \r\n",
        "  plt.figure(figsize=(20,20))\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "  plt.title(\"{} amostragem de {} \\nCaminho: {}\".format(limit, show.upper(),images_path))\r\n",
        "  plt.imshow(gallery.astype(np.uint8))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyLLgoAN81lO"
      },
      "source": [
        "for name in classNames:\r\n",
        "  show_flowers(show=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeMnqw4G9GFd"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "batch_size=128\r\n",
        "validation_split=0.2\r\n",
        "image_width = 224\r\n",
        "image_height = 224\r\n",
        "dataset_size = int(dataCount-(dataCount*0.3))\r\n",
        "validation_size =  dataset_size\r\n",
        "train_size = dataset_size\r\n",
        "\r\n",
        "train_path = '/root/.keras/datasets/flower_photos/'\r\n",
        "train_data_generator = ImageDataGenerator(rescale=1./255, \r\n",
        "                                          rotation_range=40,\r\n",
        "                                          width_shift_range=0.2,height_shift_range=0.2,\r\n",
        "                                          shear_range=0.2,zoom_range=0.2,\r\n",
        "                                          fill_mode='nearest',\r\n",
        "                                          horizontal_flip=True,validation_split=validation_split)\r\n",
        "\r\n",
        "train_datagenerator = train_data_generator.flow_from_directory(train_path,\r\n",
        "                                                    target_size=(image_width,image_height ),\r\n",
        "                                                    class_mode=\"categorical\",\r\n",
        "\r\n",
        "                                                    batch_size=batch_size,\r\n",
        "                                                    shuffle=True,\r\n",
        "                                                    subset='training')\r\n",
        "\r\n",
        "\r\n",
        "val_datagenerator = train_data_generator.flow_from_directory(train_path,\r\n",
        "                                                     target_size=(image_width,image_height),\r\n",
        "                                                     class_mode=\"categorical\",\r\n",
        "                                                     shuffle=True,\r\n",
        "                                                     batch_size=batch_size,\r\n",
        "                                                     subset='validation')\r\n",
        "print(len(classNames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV8tVEfVImBy"
      },
      "source": [
        "!ls -l /root/.keras/datasets/flower_photos/tulips/8708856019_f3be235*     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpBesX33EM5P"
      },
      "source": [
        "img = load_img('/root/.keras/datasets/flower_photos/tulips/8708856019_f3be2353a4_n.jpg') \r\n",
        "x = img_to_array(img)\r\n",
        "x = x.reshape((1,) + x.shape) \r\n",
        "\r\n",
        "i = 0\r\n",
        "for batch in train_data_generator.flow(x, batch_size=1, save_to_dir='./views', save_prefix='tulips', save_format='jpeg'):\r\n",
        "    i += 1\r\n",
        "    if i > 20:\r\n",
        "      break  #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7U-MoasD9LJ"
      },
      "source": [
        "images_path='./views/'\r\n",
        "fig = plt.figure(figsize = (20,10))\r\n",
        "index = 0    \r\n",
        "for path in os.listdir(images_path):\r\n",
        "  index += 1\r\n",
        "  plt.subplot(5, 5, index)\r\n",
        "  test_image = load_img(images_path+path, target_size=(100,150))\r\n",
        "  plt.imshow(test_image)\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqbCjXlZ-ncZ"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "runv6R6rL3UD"
      },
      "source": [
        "hub_layer =hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4', trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "444uKOUb-pKP"
      },
      "source": [
        "keras.backend.clear_session()\r\n",
        "input_shape =  (image_width,image_height,3)\r\n",
        "num_classes = len(classNames)\r\n",
        "\r\n",
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.InputLayer(input_shape=input_shape))\r\n",
        "\r\n",
        "model.add(hub_layer)\r\n",
        "\r\n",
        "model.add(keras.layers.Dropout(rate=0.2))\r\n",
        "model.add(keras.layers.BatchNormalization())\r\n",
        "model.add(keras.layers.Dense(256, activation=\"relu\"))\r\n",
        "\r\n",
        "model.add(keras.layers.Dense(num_classes, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\r\n",
        "\r\n",
        "model.compile(loss=keras.losses.CategoricalCrossentropy(from_logits=True), optimizer=keras.optimizers.RMSprop(lr=0.001, decay = 1e-3, momentum = 0.3), metrics=['accuracy'])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMljBi-1_WOP"
      },
      "source": [
        "history = model.fit(train_datagenerator,  steps_per_epoch=(train_size//batch_size),epochs= 10, validation_data=val_datagenerator,validation_steps=(validation_size//batch_size) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EefnjPgEAFpi"
      },
      "source": [
        "print(\"Train Accuracy:\\t{:.3f}%\".format(history.history['accuracy'][-1]*100))\r\n",
        "print(\"Val Accuracy:\\t{:.3f}%\".format(history.history['val_accuracy'][-1]*100))\r\n",
        "print(\"Train Loss:\\t{:.3f}\".format(history.history['loss'][-1]))\r\n",
        "print(\"Val Loss:\\t{:.3f}\".format(history.history['val_loss'][-1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXOqEWZWbky7"
      },
      "source": [
        "Procurei no google imagens de tulipas\r\n",
        "\r\n",
        "**Google**: \"**tulips** **imagesize**:224**x**224\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIz__OpPbOf8"
      },
      "source": [
        "!rm -rf ./predict\r\n",
        "\r\n",
        "tulips  = [\r\n",
        "           'https://i.pinimg.com/originals/6a/0b/60/6a0b602378370a64ec1bfdc43f270746.jpg',\r\n",
        "           'https://i.pinimg.com/originals/28/ed/49/28ed497e344619fff183780df9385ded.jpg',\r\n",
        "           'https://i.pinimg.com/originals/c4/12/3c/c4123ce3395acc8caa717ce573886ebf.jpg'\r\n",
        "]\r\n",
        "!mkdir ./predict\r\n",
        "!mkdir ./predict/images\r\n",
        "import requests\r\n",
        "for i,t in  enumerate(tulips):\r\n",
        "  r = requests.get(url)  \r\n",
        "  with open('./predict/images/'+str(i)+'.jpg', 'wb') as f:\r\n",
        "    f.write(r.content)\r\n",
        "!ls -l ./predict/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szgfeS4oiAI8"
      },
      "source": [
        "Image.open('./predict/images/1.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l_DUDcihg0t"
      },
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255)\r\n",
        "image_predict = image_generator.flow_from_directory(directory='./predict',batch_size=batch_size,\r\n",
        "            shuffle=False,color_mode='rgb',\r\n",
        "            target_size=(224,224),\r\n",
        "            class_mode=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXxxEzuijCvA"
      },
      "source": [
        "!ls -l ./predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN_oPkGHcUrb"
      },
      "source": [
        "predicts = model.predict_classes(image_predict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfYTuqJCkhdN"
      },
      "source": [
        "print('vamos ver os indices de cada flor')\r\n",
        "print(train_datagenerator.class_indices)\r\n",
        "print('as três imagens foram classificadas como:')\r\n",
        "print(predicts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZKDw0_49MLO"
      },
      "source": [
        "Antigo, mas usual: \r\n",
        "\r\n",
        "> * [Dogs x Cats Classifier | Deep Residual](https://www.kaggle.com/kernels/fork-version/38225064)\r\n",
        "\r\n",
        "> * [CIFAR 10 - Recognition in Images / to the point.](https://www.kaggle.com/kernels/fork-version/35830305)\r\n",
        "\r\n",
        "> * [Digit Recognizer - Tensorflow (RFF vs CNN)](https://www.kaggle.com/kernels/fork-version/38023473)\r\n",
        "\r\n",
        "> * [Dogs x Cats Classifier Using InceptionV3](https://www.kaggle.com/kernels/fork-version/35511267)\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}